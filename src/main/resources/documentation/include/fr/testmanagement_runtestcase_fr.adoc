=== Introduction

The run options are accessible using the menu Run > Run Test Case

image:runtestcasemenubutton.png[RunTestCaseMenu]

The different sections let the user select the test case(s) to launch and choose its execution parameters.

* Selection type
* Environment & Country
* Robot settings
* Execution settings

=== Selection Type

image:runtestselection.png[RunTestSelection]

Manual selection let the user select one or several test cases using the filters.

image:extendedtestcasefilters.png[ExtendedTestCaseFilters]

Campaign selection let the user select a campaign from a dropdown menu. Clicking 'load' button display the selected test cases in the section below.

image:campaignselection.png[CampaignSelection]

=== Environment & Country

By default, in automatic mode, you can select the preconfigured environment.

Warning: The environment and countries must be configured for the related applications. Besides, the testcase attributes override the configuration (e.g. Active in PROD)

image:runenvselect.png[EnvironmentCountries]

You can also define yourself the url of the application to test. In that case, the environment still needs to be defined in order to determine which data for the property calculation to use.
url can have different format :

* simple string : http://host
* Composed string for multiple applications using : and ; separators : APP1:qa.cerberus-testing.org;APP2:toto.cerberus-testing.org
* Composed string for multiple applications using JSON format : {"APP1":"https://qa.cerberus-testing.org:443","APP2":"http://toto.cerberus-testing.org"}

image:runenvselect2.png[EnvironmentCountries]

Last you need to select one or more countries.

image:runcountryselect.png[EnvironmentCountries]

=== Robots settings

image:runrobotsettings.png[RunRobotSettings]

The robots settings can be linked to a campaign. If so, the robot(s) will be automatically selected when the corresponding campaign is loaded.

However, if the user changes this value, it will be overriden by his selection.

'Save Robot Preferencies' button save these settings in the browser cache of the device.

The selected robot can be edited using the left button. A new robot can be created using the right one. 

=== Execution settings

image:runexecutionsettings_en.png[RunExecutionSettings, 500, 500]

* Tag : regroup all the execution in the same tag. It help identify this execution for reporting sake. If no value, the tag will be a timestamp. you can use %USER% and %TIMESTAMP% variable in this field.
* Verbose : Verbose define how much trace information will be output on the execution. The higher the level is from 0 to 2 the more information will be and the slower the testcase will be executed.

|=== 

| *Trace \ Verbose Level* | *0* | *1*  | *2*   
| Chrome & Firefox display | no (headless) | yes | yes
| JSON INFO Application Server logs | no | yes | yes

|=== 

* Screenshot : define if screenshots and video have to be taken and the frequency.
* Page Source : define if Page source have to be taken and the frequency.
* Robot Log : define if robot (Selenium or Appium) log will be taken.
* Timeout : define the maximum time (in ms) to spent in an action or control. Correspond to the time Cerberus will wait until it consider that a field or object is not available.
* Retries : Defined the number of retries for each test cases. A retry is a re submission of a testcase (in the queue) if its status is different from OK.
* Priority : define the priority for all the test cases (reminder: the lowest (=0) the most important). Default value is 1000. Tips: Use 0 priority only when relaunching manually a test case. 
* Manual Execution : define the test case execution type: Y : manual, N : Automatic, A : Automaticly determined from test case. default value is 'N'

|=== 

| *Execution parameter \ Test Case Group* | *AUTOMATED* | *MANUAL*  | *PRIVATE*   
| N | Automated execution | Automated execution | Automated execution
| Y | Manual execution | Manual execution | Manual execution
| A | Automated execution | Manual Execution | Automated execution

|=== 

=== Execution result status

image:executionstatus.png[ExecutionStatus]

Here is a summary of all execution status with their corresponding meanings.

* OK : The execution was performed correctly and all controls were OK.
* KO : The execution was performed correcly and at least one control failed resulting a global KO. That means that a bug needs to be reported to development teams.
* FA : The execution did not performed correctly and needs a correction from the team that is in charge of managing the testcases. It couls be a failed SQL or action during the test.
* NA : Test could not be executed as a data could not be retreived. That probably means that the test is not possible in the current environment/status.
* NE : Test Case was not executed (following a condition execution).
* WE : Test Case was not yet executed (waiting a manual execution).
* PE : Test Case is currently running.
* QU : Test Case is still waiting in the queue for ressources or constrains to be released.
* QE : Test Case failed in the queue and will not be triggered.
* CA : Test Case has been cancelled by user.
